{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7522f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load data\n",
    "TRAIN_PATH = \"/kaggle/input/summer-analytics-mid-hackathon/hacktrain.csv\"\n",
    "TEST_PATH = \"/kaggle/input/summer-analytics-mid-hackathon/hacktest.csv\"\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "ndvi_columns = [col for col in train.columns if col.endswith('_N')]\n",
    "\n",
    "# Impute missing values (mean or median both work well)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_ndvi = imputer.fit_transform(train[ndvi_columns])\n",
    "X_test_ndvi = imputer.transform(test[ndvi_columns])\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train_ndvi, columns=ndvi_columns)\n",
    "X_test_df = pd.DataFrame(X_test_ndvi, columns=ndvi_columns)\n",
    "\n",
    "# Feature Engineering (proven set)\n",
    "def extract_features(df):\n",
    "    features = pd.DataFrame()\n",
    "    features['mean'] = df.mean(axis=1)\n",
    "    features['std'] = df.std(axis=1)\n",
    "    features['min'] = df.min(axis=1)\n",
    "    features['max'] = df.max(axis=1)\n",
    "    features['median'] = df.median(axis=1)\n",
    "    features['range'] = features['max'] - features['min']\n",
    "    features['q25'] = df.quantile(0.25, axis=1)\n",
    "    features['q75'] = df.quantile(0.75, axis=1)\n",
    "    features['iqr'] = features['q75'] - features['q25']\n",
    "    features['first'] = df.iloc[:, 0]\n",
    "    features['last'] = df.iloc[:, -1]\n",
    "    features['diff'] = df.iloc[:, -1] - df.iloc[:, 0]\n",
    "    features['slope'] = (df.iloc[:, -1] - df.iloc[:, 0]) / (df.shape[1] - 1)\n",
    "    return features\n",
    "\n",
    "train_features = extract_features(X_train_df)\n",
    "test_features = extract_features(X_test_df)\n",
    "\n",
    "# Combine raw NDVI + engineered features\n",
    "X_train_final = np.hstack([X_train_ndvi, train_features.values])\n",
    "X_test_final = np.hstack([X_test_ndvi, test_features.values])\n",
    "\n",
    "# Encode target\n",
    "y_train = train['class'].astype('category').cat.codes\n",
    "label_map = dict(enumerate(train['class'].astype('category').cat.categories))\n",
    "\n",
    "# Model - tune C for best validation performance\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LogisticRegression(\n",
    "        max_iter=3000,\n",
    "        multi_class='multinomial',\n",
    "        solver='lbfgs',\n",
    "        random_state=42,\n",
    "        C=1.5  # Slightly less regularization, can tune between 1.0 and 2.0\n",
    "    ))\n",
    "])\n",
    "pipeline.fit(X_train_final, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = pipeline.predict(X_test_final)\n",
    "pred_labels = pd.Series(y_pred).map(label_map)\n",
    "\n",
    "# Submission\n",
    "submission = pd.DataFrame({'ID': test['ID'], 'class': pred_labels})\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "print(\"ðŸŽ¯ Final optimized submission saved!\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
